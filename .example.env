# ===================================
# Insight Capsule Configuration
# ===================================

# ===================================
# Local LLM Settings (Ollama)
# ===================================
# Use local LLM via Ollama for privacy and offline operation
USE_LOCAL_LLM=true

# Ollama API URL (default: http://localhost:11434)
LOCAL_LLM_URL=http://localhost:11434

# Model to use with Ollama (e.g., llama3.2, mistral, etc.)
# Run: ollama pull llama3.2
LOCAL_LLM_MODEL=llama3.2

# ===================================
# External LLM Settings (OpenAI)
# ===================================
# Only needed if USE_LOCAL_LLM=false
# Get your key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=

# ===================================
# Whisper Transcription Settings
# ===================================
# Model size: tiny, base, small, medium, large
# Larger = more accurate but slower
WHISPER_MODEL=base

# ===================================
# Text-to-Speech Settings
# ===================================
# Enable/disable voice feedback
TTS_ENABLED=true

# Speech rate (words per minute, typically 150-200)
TTS_RATE=170

# Enable fallback beep sound if TTS fails
TTS_FALLBACK_BEEP=true

# ===================================
# Audio Recording Settings
# ===================================
# Enable automatic silence detection to stop recording
# When enabled, recording will auto-stop after SILENCE_DURATION seconds of silence
SILENCE_DETECTION_ENABLED=false

# Amplitude threshold for silence detection (0.0-1.0)
# Lower values = more sensitive to quiet sounds
SILENCE_THRESHOLD=0.01

# Duration of silence (in seconds) before auto-stopping
# Recommended: 3.0-10.0 seconds
SILENCE_DURATION=3.0

# ===================================
# Pipeline Settings
# ===================================
# Maximum words in generated insight capsule
MAX_CAPSULE_WORDS=400

# Temperature for LLM generation (0.0-1.0, higher = more creative)
DEFAULT_TEMPERATURE=0.7